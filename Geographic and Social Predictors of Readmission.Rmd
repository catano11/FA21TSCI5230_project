---
title: "Geographic and Social Predictors of Readmission"
author: "Chapapas, Holly, Munoz, Edgar, Nie, Jia & Catano, Omar Gabriel"
date: "2021-11-17"
abstract:  "[Provide a summary of objectives, study design, sample size, predictors, outcome, statistical analysis, results, and conclusions.]"
output:
  html_document: default
  word_document:
    reference_docx: templates/template.docx
editor_options: 
  chunk_output_type: console
bibliography: citations.bib
csl: apa-6th-edition.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

packageList <- c("knitr","Publish","ggplot2","rio","GGally","dplyr","pander","readr","synthpop", "rmarkdown", "readxl", "tibble", "broom", "scales", "ModelMetrics")
for(package in packageList){
  if(!require(package,character.only = TRUE)){
    install.packages(package);require(package,character.only = TRUE);}
}

load('data/Analysis.Rdata');
dtest <- readRDS('data/dtest.Rds');
cm <- comma_format()

# Use the following in the console to pull from the main repository:
# git remote add upstream https://github.com/bokov/FA21TSCI5230_project
# git pull upstream main
```

# Preliminary Results

## Data

As proof of principle, we used AHRQ-curated census data from the years 2015 and 2016, which we will extend to all available years during the proposed study. Using zipcode tabulation areas (ZCTAs) we crosswalked the AHRQ data to the Social Deprivation Index [@Butler2012] and to our own calculations of percentages of hospital discharges that did not result in readmissions.

## Analysis

Before viewing the merged dataset in any way, we randomly assigned each ZCTA to a training (N=`r  cm(nrow(dtrain))`) or testing (N= `r cm(nrow(dtest))`) subset (each with 50% likelihood). Variable selection and all other decisions about data analysis were made using only the training subset, having blinded ourselves to the testing subset until the entire analysis pipeline was finalized [@Boldanova2021].

Our previous research suggests that the following socieconomic variables are possible predictors of readmission (the variable named NoReadmission  ) : ACS_PER_CAPITA_INCOME, ACS_PCT_POSTHS_ED, ACS_MEDIAN_HOME_VALUE, ACS_PCT_MEDICAID_ANY, ACS_PCT_DISABLE, and sdi_score. However, we had no reason to believe these are the only relevant variables nor that their effect is additive (i.e. we cannot exclude the possibility that the effect of a variable might increase or decrease depending on the values of other variables).
We used bi-directional stepwise selection with the Bayes Information Criterion (BIC) to select the terms for a regression model. The models considered ranges from no predictors to all available variables with all possible two-way interactions. The model selected through this process was as follows:


```{r regression model, echo=FALSE}
#' echo=FALSE will prevent the printing of the R code that generated the plot
#' ## Model Summary



fit<- readRDS(file="data/analysis_fit.RDS")
fitBIC<- readRDS(file="data/analysis_fitBIC.RDS")

#' Fitting data to appropriate statistic linear model with our predictors
# fit <- lm(_______ ~ ACS_PER_CAPITA_INCOME + ACS_PCT_POSTHS_ED + ACS_MEDIAN_HOME_VALUE + ACS_PCT_MEDICAID_ANY + ACS_PCT_DISABLE + sdi_score, data = ________);
# summary(fit);
#' Provide a clean version of the summary - both produce the same results
# summary(fit) %>% tidy;
# fit %>% tidy;
#' Show a quick look at all of the summary statistics
# glance(fit);

#' Create a 'null' model that does not specify predictors
# fit0 <- lm(________ ~ 1, data = ________);
# summary(fit0);
# summary(fit0) %>% tidy;
# fit0 %>% tidy;
# glance(fit0);

# When using lm repeatedly you can use '.~' to keep the original outcome and '~.' to keep the original predictors
#'
#' Create an all encompassing model for your predictors
# Include some interaction terms with interaction model: 'OUTCOME ~ PRED1*PRED2*PRED3 ...'
# For all 2 way interactions : '~ (A+B+C)^2', for all 3 way interactions: '~ (A+B+C)^3'
# Additive model for note: 'OUTCOME ~ PRED1 + PRED2 + PRED3 + ...'
# fit1 <- lm(________ ~ (ACS_PER_CAPITA_INCOME + ACS_PCT_POSTHS_ED + ACS_MEDIAN_HOME_VALUE + ACS_PCT_MEDICAID_ANY + ACS_PCT_DISABLE + sdi_score)^2, data = ________);

# If you forget the arguments for a function you can check it with args()
# i.e. args(step)
#' Create a BIC stepwise regression
# fitBIC <- step(fit, scope = list(lower = fit0, upper = fit1), scale = 0, direction = "both", k = log(_));
# summary(fitBIC) %>% tidy;

#' Compare the models
# anova(fit0, fit1);
# plot(fit1)
# plot(data$________, predict(fit1,dat1test)-dat1test$________)
# plot(dat1train$________, predict(fit1)-dat1train$________)

#' [residual plots go here]'

#' [plot of predicted vs observed values goes here]'

```

We then made predictions on out-of-sample data (i.e. the training set) without re-fitting or altering the original model and got the following result:

```{r training model, echo=FALSE}
#' echo=FALSE will prevent the printing of the R code that generated the plot
plot(dtest$NOREADMISSION ~ predict(fit, dtest))

fitRMSE <- ModelMetrics::rmse(predict(fit, dtest), dtest$NOREADMISSION)
table(is.na(predict(fit)))

'[plot of predicted vs observed training values goes here]'

```
The root mean square error is `r fitRMSE`
\newpage

# References


